{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "id": "2b90ee52-5e80-4ecb-80a3-9c3758d7803d",
      "cell_type": "markdown",
      "source": "1. Discuss the scenarios where multithreading is preferable to multiprocessing and scenarios where multiprocessing is a better choice.",
      "metadata": {}
    },
    {
      "id": "1e04c378-98b9-4cc7-9023-caaf50e6826a",
      "cell_type": "markdown",
      "source": "Multithreading involves running multiple threads within the same process, sharing the same memory space. Threads are lightweight and can share data easily, but they are constrained by Python’s Global Interpreter Lock (GIL) in CPython, which limits concurrent execution of CPU-bound tasks. However, threads are well-suited for I/O-bound tasks.\n\nWhen Multithreading is Preferable:\nI/O-Bound Tasks (e.g., file operations, web requests, database queries):\n\nWhen your program spends much of its time waiting for external resources (e.g., reading from a file, making HTTP requests, or waiting for a response from a database), multithreading can be a good choice. Threads can be used to perform other tasks while waiting for I/O operations to complete, thus improving efficiency.\n\nThreads share the same memory space, making data sharing between threads faster and easier. If the program needs frequent interaction with shared data and can operate without significant risk of data corruption or contention, multithreading is ideal.\n\nLow Overhead and Lightweight Tasks:\n\nThreads are typically more lightweight than processes. If the task involves small operations or frequent context switching, the overhead of creating new threads is less than creating new processes.\n\nReal-Time or Interactive Applications:\n\nIn scenarios where user interaction is required, multithreading can be useful because it allows the program to remain responsive to user input (e.g., updating the user interface while performing background tasks).\n\n\nMultiprocessing, in contrast, involves running multiple processes, each with its own memory space. This approach is more expensive in terms of overhead compared to multithreading but allows true parallelism, which is useful for CPU-bound tasks, especially in a multi-core CPU environment.\n\nWhen Multiprocessing is Preferable:\nCPU-Bound Tasks (e.g., number crunching, machine learning, data analysis):\n\nWhen the task is heavily CPU-bound (i.e., it involves computations that use a lot of processing power), multiprocessing can fully leverage multiple CPU cores. Each process runs in its own memory space and can execute on a separate core, bypassing the Global Interpreter Lock (GIL) limitation in Python.\n\nTrue Parallelism (e.g., tasks that need full CPU utilization):\n\nIf your application needs to run multiple tasks simultaneously and make full use of all available cores, multiprocessing is a better choice. Each process can run in parallel on separate CPU cores, achieving significant performance improvements for computationally intensive tasks.\n\nAvoiding the Global Interpreter Lock (GIL):\n\nThe GIL in Python prevents multiple threads from executing Python bytecodes in parallel. This means that multithreading in CPython does not achieve true parallelism for CPU-bound tasks. In contrast, multiprocessing bypasses the GIL, allowing each process to run independently on its own CPU core.\n\nIsolation of Processes:\n\nMultiprocessing is beneficial when processes need to be isolated from each other. Since each process has its own memory space, it is safer when dealing with tasks that may involve memory corruption or when you want to avoid issues with data integrity that may arise with shared memory in multithreading.\n\nFault Tolerance:\n\nIn a multiprocessing setup, if one process crashes, it doesn’t affect the others. This is particularly useful for distributed computing or when working with independent tasks that should continue execution even if one process fails.",
      "metadata": {}
    },
    {
      "id": "4e145549-bfa8-4693-968c-1f51152872f4",
      "cell_type": "markdown",
      "source": "2. Describe what a process pool is and how it helps in managing multiple processes efficiently.",
      "metadata": {}
    },
    {
      "id": "075f7754-58a8-42ed-965d-a346b185f329",
      "cell_type": "markdown",
      "source": "A process pool is a collection of worker processes that are managed together to perform a set of tasks concurrently. Rather than spawning new processes for each task (which can be costly in terms of time and system resources), a process pool allows a fixed number of worker processes to be created ahead of time, and tasks can be assigned to these workers as needed.\n\nThe main idea behind a process pool is to reuse a set of pre-existing processes to handle a workload, which improves the efficiency and scalability of managing multiple processes in parallel.\n\nIt helps in managing multiple processes efficiently by, \n\nInitialization: A pool of worker processes is created when the program starts. The number of processes in the pool is typically specified when the pool is created (or defaults to the number of CPU cores if not specified).\n\nTask Submission: Tasks (which could be function calls or jobs) are submitted to the pool. Each task is usually represented by a callable (e.g., a function or a method).\n\nTask Distribution: When a task is submitted, the process pool manager assigns the task to an idle worker process from the pool. If no processes are idle, the task waits in a queue until a process becomes available.\n\nWorker Process Execution: The worker process performs the task, runs the corresponding function, and when done, returns the result.\n\nResult Handling: The result is collected from the worker process and made available to the calling code. In many cases, the result is provided through a future or callback mechanism.\n\nReusing Processes: Once a worker process completes its task, it becomes idle again and is available to pick up new tasks from the queue.\n\nBenefits of Using a Process Pool\nEfficiency:\n\nReduced overhead: Creating and destroying processes can be expensive, especially in systems where process creation is slow. A process pool avoids the cost of repeatedly forking new processes by reusing the same set of processes.\nConcurrency: The pool allows you to execute multiple tasks concurrently across different CPU cores, without the need for manual management of processes.\nLoad Management:\n\nScalable workload: By using a pool of worker processes, you can efficiently handle a large number of tasks without overwhelming the system. The process pool can be sized based on the number of available CPU cores or according to system load.\nTask queue: If the pool runs out of idle processes, tasks can wait in a queue until a worker becomes available. This allows you to manage the load effectively without overloading the system.\nSimplified Error Handling:\n\nIsolation: Each process in the pool is isolated from others. If one process crashes or encounters an error, it doesn’t affect other tasks or processes in the pool. This makes error handling easier and more robust.\nResource Management:\n\nControlled parallelism: Since the pool size is limited, you can control how many processes are running in parallel, avoiding resource exhaustion (e.g., memory or CPU).\nBalanced resource usage: The pool can be tuned to match the number of available CPU cores, ensuring optimal resource usage without overloading the system.\nFaster Execution:\n\nReduced wait times: Because processes are already available in the pool, tasks can start executing immediately rather than waiting for a new process to be created.",
      "metadata": {}
    },
    {
      "id": "2aaba355-788d-43e0-9812-56000c14be37",
      "cell_type": "markdown",
      "source": "3. Explain what multiprocessing is and why it is used in Python programs.\n",
      "metadata": {}
    },
    {
      "id": "fceba829-e477-4e04-a73f-23794c18e679",
      "cell_type": "markdown",
      "source": "Multiprocessing is a technique in Python that allows a program to execute multiple processes simultaneously, leveraging multiple CPU cores. This is particularly helpful for tasks that require substantial computational power, as it enables Python programs to perform parallel processing.\n\nPython has a Global Interpreter Lock (GIL), which restricts the execution of multiple threads within the same process to one at a time. This makes multithreading in Python less effective for CPU-bound tasks, as threads are forced to take turns. However, since separate processes have their own memory space and don't share the GIL, they can run concurrently on different cores. This enables Python to better leverage the capabilities of multi-core CPUs.\n\nBenefits of Multiprocessing\nTrue Parallelism: Unlike multithreading, where threads share memory space and must wait for access to resources, multiprocessing allows each process to execute independently on a separate CPU core.\n\nImproved Performance: Multiprocessing can significantly reduce execution time for tasks that can be split into independent parts, such as processing large data sets, running complex calculations, or performing I/O operations in parallel.\n\nFault Isolation: Since each process runs independently, errors in one process don’t affect others, making programs more robust in handling individual process failures.\n\nHow It Works in Python\nPython’s multiprocessing module provides an interface to spawn and manage multiple processes. Some commonly used features include:\n\nProcess: Allows you to create a new process with its own resources.\nPool: Enables you to manage multiple processes efficiently, dividing tasks among them.\nQueues and Pipes: Facilitate communication between processes, enabling them to share results or messages.\nShared Memory: Allows processes to share data, which is useful when they need to work on shared resources without excessive copying.",
      "metadata": {}
    },
    {
      "id": "aa42497c-fe06-4568-9bce-823d8ea57b85",
      "cell_type": "markdown",
      "source": "4. Write a Python program using multithreading where one thread adds numbers to a list, and another thread removes numbers from the list. Implement a mechanism to avoid race conditions using\nthreading.Lock.",
      "metadata": {}
    },
    {
      "id": "f3c7aa54-36e0-48b0-8fc9-60e2f69e2043",
      "cell_type": "markdown",
      "source": "Here's a Python program that uses the threading module to demonstrate multithreading with a Lock to avoid race conditions. In this example, one thread continuously adds numbers to a shared list, while another thread continuously removes numbers from the same list. Using threading.Lock, we ensure that only one thread can access the list at a time, preventing race conditions.",
      "metadata": {}
    },
    {
      "id": "945aba01-2702-4f3f-bc2f-7de15172a9a2",
      "cell_type": "code",
      "source": "import threading\nimport time\n\n# Shared list and lock\nshared_list = []\nlock = threading.Lock()\n\n# Function for adding numbers to the list\ndef add_to_list():\n    for i in range(1, 11):  # Let's add 10 numbers as an example\n        lock.acquire()  # Acquire the lock before accessing the list\n        try:\n            shared_list.append(i)\n            print(f\"Added {i} to list. List now: {shared_list}\")\n        finally:\n            lock.release()  # Release the lock\n        time.sleep(0.1)  # Simulate some processing delay\n\n# Function for removing numbers from the list\ndef remove_from_list():\n    for _ in range(10):  # Attempt to remove 10 items\n        lock.acquire()  # Acquire the lock before accessing the list\n        try:\n            if shared_list:\n                removed = shared_list.pop(0)\n                print(f\"Removed {removed} from list. List now: {shared_list}\")\n            else:\n                print(\"List is empty, nothing to remove.\")\n        finally:\n            lock.release()  # Release the lock\n        time.sleep(0.15)  # Simulate some processing delay\n\n# Creating threads\nthread1 = threading.Thread(target=add_to_list)\nthread2 = threading.Thread(target=remove_from_list)\n\n# Starting threads\nthread1.start()\nthread2.start()\n\n# Waiting for both threads to finish\nthread1.join()\nthread2.join()\n\nprint(\"Final list:\", shared_list)\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "97e5099e-974b-460b-bd32-839c8228f75d",
      "cell_type": "markdown",
      "source": "5. Describe the methods and tools available in Python for safely sharing data between threads and processes.",
      "metadata": {}
    },
    {
      "id": "0785a3ea-d4f0-4b59-aa30-d9d54ca1b57d",
      "cell_type": "markdown",
      "source": "In Python, sharing data between threads and processes can be tricky, especially when dealing with concurrency and parallelism. Both threading and multiprocessing present challenges, particularly with race conditions, where multiple threads or processes attempt to access shared data at the same time. To handle these challenges safely, Python provides various methods and tools.\n\n1. Threading: Tools for Safe Data Sharing\n\nLock: Allows only one thread to access shared data at a time, preventing race conditions.\n\nRLock (Reentrant Lock): Similar to Lock, but allows the same thread to acquire the lock multiple times, useful for nested or recursive functions.\n\nSemaphore: Controls access by permitting a set number of threads to access shared data simultaneously.\n\nCondition: Provides a way for threads to wait for specific conditions or notify others when a condition is met, useful for coordinating thread actions.\n\n\n2. Multiprocessing: Tools for Safe Data Sharing\n\nQueue: A FIFO queue that allows multiple processes to safely exchange data by adding and retrieving items.\n\nPipe: Provides a two-way connection between processes, enabling them to communicate by sending messages.\n\nManager: Offers shared objects (e.g., lists, dictionaries) that processes can access and modify concurrently.\n\nValue and Array: Specialized shared memory objects for simple data types (e.g., integers) and fixed-size arrays, enabling safe sharing between processes.\n\n\nAdditional Considerations\n\nDeadlock Prevention: Ensure proper lock usage to prevent situations where processes or threads block each other indefinitely.\n\nThread-Safe Data Structures: Use built-in thread-safe structures like Queue for easier management without manually handling locks.\n\nMinimize Global Variables: Avoid global variables to reduce complexity and prevent accidental race conditions.",
      "metadata": {}
    },
    {
      "id": "6bed98ff-798a-4064-be70-65c3bdee3e29",
      "cell_type": "markdown",
      "source": "6. Discuss why it’s crucial to handle exceptions in concurrent programs and the techniques available for doing so.",
      "metadata": {}
    },
    {
      "id": "014e10d2-b026-4e33-b959-ef74648932f3",
      "cell_type": "markdown",
      "source": "Handling exceptions in concurrent programs is crucial because it ensures the stability, reliability, and robustness of applications that involve multiple threads or processes. In concurrent programs, an unhandled exception in one thread or process can lead to partial failures, leaving other threads or processes in inconsistent states, causing deadlocks, resource leaks, or incorrect program results. Here’s a look at why this is important and techniques available for handling exceptions in such scenarios.\n\nTechniques for Exception Handling in Concurrent Programs\n1. Using Try-Except Blocks\nThreads: Wrap the code within each thread in a try-except block to catch exceptions locally. This helps isolate failures within individual threads, allowing them to handle exceptions without affecting other threads.\nProcesses: Similarly, use try-except blocks in each process to catch exceptions individually.\n\n2. Thread/Process-Wide Exception Logging\nLogging Exceptions: Log exceptions within each thread or process to capture errors as they happen. This can be done using Python’s logging module or by writing errors to a shared data structure (e.g., a queue) for centralized logging.\nCallback Functions: Some libraries allow specifying callback functions to handle errors when threads or processes fail, improving centralized error handling.\n\n3. Using Concurrent Futures\nThe concurrent.futures module in Python provides a higher-level API for working with threads and processes.\nFuture.result() Method: By calling result() on a Future object (returned by ThreadPoolExecutor or ProcessPoolExecutor), you can capture exceptions raised in the task, as they will propagate to the main thread when result() is called.\nException Handling with as_completed(): Use as_completed() to handle results or exceptions as tasks complete, allowing for more granular exception management.\n\n4. Using a Supervisory Thread/Process\nWatchdog Pattern: Implement a “watchdog” thread or process to monitor others and take corrective actions if they fail. This can be achieved by having the main program supervise worker threads/processes, checking their status periodically.\nHealth Checks: Periodically check the state of threads or processes and restart or alert if one is unresponsive or fails unexpectedly.\n\n5. Error Handling with Queues\nShared Queue for Errors: Use a shared queue to collect error messages from multiple threads or processes. Each thread or process writes its exception details to the queue, and a separate thread or process reads from the queue to handle or log errors centrally.\nGraceful Termination: When errors are detected via the queue, the main program can trigger a controlled shutdown or cleanup.\n\n6. Ensuring Resource Cleanup with finally Blocks\nIn try-except-finally structures, the finally block ensures that resources (e.g., files, locks) are released even if an exception occurs. This is important for concurrent programs to prevent resource leaks.\nFor example, use finally to release locks, close files, or clean up memory in each thread or process.\n\n7. Fail-Fast Strategy\nImmediate Exit on Failure: In some applications, if one thread or process fails, it’s safer to terminate the entire program to avoid inconsistent states or partial results. This strategy can prevent complex debugging in cases where continued execution may lead to further errors or corruption.",
      "metadata": {}
    },
    {
      "id": "6fbd2c81-8d22-40a3-a870-cd14f832e328",
      "cell_type": "markdown",
      "source": "7. Create a program that uses a thread pool to calculate the factorial of numbers from 1 to 10 concurrently.\nUse concurrent.futures.ThreadPoolExecutor to manage the threads.",
      "metadata": {}
    },
    {
      "id": "8afbca1a-2097-412b-91f7-547600ffe6fc",
      "cell_type": "markdown",
      "source": "Here’s a Python program that uses concurrent.futures.ThreadPoolExecutor to calculate the factorial of numbers from 1 to 10 concurrently. This program demonstrates how to create a thread pool and submit tasks to calculate factorials for each number. The ThreadPoolExecutor helps in managing the threads and makes it easy to retrieve the results once all computations are done.",
      "metadata": {}
    },
    {
      "id": "0285eaf7-f6f1-4193-b4da-d93bb52f445d",
      "cell_type": "code",
      "source": "from concurrent.futures import ThreadPoolExecutor, as_completed\nimport math\n\n# Function to calculate the factorial of a number\ndef calculate_factorial(n):\n    return math.factorial(n)\n\n# List of numbers to calculate factorial for\nnumbers = range(1, 11)\n\n# Using ThreadPoolExecutor to manage a pool of threads\nwith ThreadPoolExecutor() as executor:\n    # Submit tasks to the thread pool\n    futures = {executor.submit(calculate_factorial, number): number for number in numbers}\n    \n    # Collect and print results as they complete\n    for future in as_completed(futures):\n        number = futures[future]\n        try:\n            result = future.result()\n            print(f\"Factorial of {number} is {result}\")\n        except Exception as e:\n            print(f\"An error occurred calculating factorial of {number}: {e}\")\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "002b65b0-fa95-47f9-b010-3de2f274788a",
      "cell_type": "markdown",
      "source": "8. Create a Python program that uses multiprocessing.Pool to compute the square of numbers from 1 to 10 in\nparallel. Measure the time taken to perform this computation using a pool of different sizes (e.g., 2, 4, 8\nprocesses).",
      "metadata": {}
    },
    {
      "id": "f6ed19ae-726b-4271-91b3-464a377c2c24",
      "cell_type": "markdown",
      "source": "Here's a Python program that uses multiprocessing.Pool to compute the squares of numbers from 1 to 10 in parallel. This program measures the time taken to perform the computation with pools of different sizes (2, 4, and 8 processes).",
      "metadata": {}
    },
    {
      "id": "1d6273d5-4892-403b-b6d3-5a3765ed3bb9",
      "cell_type": "code",
      "source": "from multiprocessing import Pool\nimport time\n\n# Function to calculate the square of a number\ndef calculate_square(n):\n    return n * n\n\n# List of numbers to calculate squares for\nnumbers = range(1, 11)\n\n# Function to measure computation time for different pool sizes\ndef compute_squares_with_pool(pool_size):\n    start_time = time.time()  # Start timer\n    \n    with Pool(processes=pool_size) as pool:\n        results = pool.map(calculate_square, numbers)\n    \n    end_time = time.time()  # End timer\n    computation_time = end_time - start_time\n    return results, computation_time\n\n# Dictionary to store results for each pool size\npool_sizes = [2, 4, 8]\ncomputation_times = {}\n\n# Perform computations with different pool sizes and record results\nfor size in pool_sizes:\n    results, time_taken = compute_squares_with_pool(size)\n    computation_times[size] = time_taken\n    print(f\"Pool Size: {size} | Results: {results} | Time Taken: {time_taken:.5f} seconds\")\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "89dbfb2d-fc77-48a2-ba39-84edc3d820b8",
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}